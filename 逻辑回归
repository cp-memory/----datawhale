1.逻辑回归与线性回归的联系与区别：逻辑回归与线性回归都属于广义线性回归模型
                                区别在于线性回归要求连续性数据变量，而逻辑回归要求必须是分类变量。
2.逻辑回归的原理:它是分类算法而不是回归算法，在线性回归的基础上加入sigmoid函数，达到非线性的效果。
3.逻辑回归损失函数推导及优化：
P(y(i)=1|x(i);θ)=hθ(x(i))
P(y(i)=0|x(i);θ)=1−hθ(x(i))
P(y(i)|x(i);θ)=hθ(x(i))y(i)(1−hθ(x(i)))(1−y(i))P(y(i)|x(i);θ)=hθ(x(i))y(i)(1−hθ(x(i)))(1−y(i))
L(θ)=P(y⃗ |x;θ)=∏mi=1P(y(i)|x(i);θ)=∏mi=1hθ(x(i))y(i)(1−hθ(x(i)))(1−y(i))L(θ)=P(y→|x;θ)=∏i=1mP(y(i)|x(i);θ)=∏i=1mhθ(x(i))y(i)(1−hθ(x(i)))(1−y(i))
logL(θ)=∑mi=1y(i)loghθ(x(i))+(1−y(i))log(1−hθ(x(i)))logL(θ)=∑i=1my(i)loghθ(x(i))+(1−y(i))log(1−hθ(x(i)))
优化：计算梯度并用高级优化算法.

4.正则化与模型评估指标：
正则化应对过拟合问题，可以起到损失函数和复杂度之间的平衡；L1范数：L1范数在正则化的过程中会趋向于产生少量的特征，而其他的特征都是0（L1会使得参数矩阵变得稀疏）。因此L1不仅可以起到正则化的作用，还可以起到特征选择的作用。
L2范数：L2范数是通过使权重衰减，进而使得特征对于总体的影响减小而起到防止过拟合的作用的。L2的优点在于求解稳定、快速。
模型评估指标：准确率和召回率。

5.逻辑回归的优缺点：
                 优点：形式简单，模型简明，输出范围小，训练速度快。
                 缺点：容易欠拟合，决策边界不好画，不好处理特征之间相关性。
6.sklearn参数：
              penalty：惩罚项，str类型，可选参数为l1和l2，默认为l2
              c：正则化系数λ的倒数                 
